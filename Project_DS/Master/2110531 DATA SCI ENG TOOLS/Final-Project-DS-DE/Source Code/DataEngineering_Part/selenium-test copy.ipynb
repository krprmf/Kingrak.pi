{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumbase import Driver\n",
    "from seleniumbase import page_actions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Driver(uc=True)\n",
    "driver.get(\"https://www.frontiersin.org/articles/10.3389/frai.2022.1049584/full\")\n",
    "# print(res)\n",
    "x = page_actions.get_text(driver, \"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.split(\"Author keywords\"))\n",
    "print(len(x.split(\"Author keywords\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopus API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybliometrics.scopus import AbstractRetrieval, SerialSearch, ScopusSearch\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from confluent_kafka import Producer, Consumer, KafkaError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '464f17417c90aff3a9e077e3952aece0'\n",
    "\n",
    "headers = {\n",
    "    'Accept':'application/json',\n",
    "    'X-ELS-APIKey': '27594a4c1478f17ac42280535ab20312'\n",
    "}\n",
    "\n",
    "attributes = [\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "    \"affiliation\",\n",
    "    \"authors\",\n",
    "    \"authkeywords\",\n",
    "    \"publicationName\",\n",
    "    \"publisher\",\n",
    "    \"subject_areas\",\n",
    "    \"subtypedescription\",\n",
    "    \"citedby_count\",\n",
    "    \"references\",\n",
    "    \"issn\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_info(papers):\n",
    "    all_papers = []\n",
    "    count_none = 0\n",
    "    for paper in tqdm(papers):\n",
    "        data_dict = {}\n",
    "        if paper[\"eid\"]:\n",
    "            ab = AbstractRetrieval(paper[\"eid\"], view='FULL')\n",
    "            for attr in attributes:\n",
    "                if hasattr(ab, attr):\n",
    "                    value = getattr(ab, attr)\n",
    "                    if value is not None:\n",
    "                        if attr == \"affiliation\":\n",
    "                            uni_aff = []\n",
    "                            country_aff = []\n",
    "                            for aff in value:\n",
    "                                uni_aff.append(aff.name)\n",
    "                                country_aff.append(aff.country)\n",
    "                            data_dict[\"University\"] = list(set(uni_aff))\n",
    "                            data_dict[\"Country\"] = list(set(country_aff))\n",
    "                        elif attr == \"authors\":\n",
    "                            index_author = []\n",
    "                            for author in value:\n",
    "                                index_author.append(author.indexed_name)\n",
    "                            data_dict[\"Index_authors\"] = list(set(index_author))\n",
    "                        elif attr == \"subject_areas\":\n",
    "                            subject_area = []\n",
    "                            subject_area_code = []\n",
    "                            for subj in value:\n",
    "                                subject_area.append(subj.area)\n",
    "                                subject_area_code.append(subj.abbreviation)\n",
    "                            data_dict[\"Subject_Area\"] = list(set(subject_area))\n",
    "                            data_dict[\"Subject_Area_Code\"] = list(set(subject_area_code))\n",
    "                        elif attr == \"references\":\n",
    "                            data_dict[\"references_number\"] = len(ab.references)\n",
    "                            data_dict[\"references\"] = ab.references\n",
    "                        elif attr == \"issn\":\n",
    "                            try:\n",
    "                                pattern = r'\\b\\d{4}\\b'\n",
    "                                match = re.search(pattern, ab.abstract)\n",
    "                                if match:\n",
    "                                    year = match.group()\n",
    "                                else:\n",
    "                                    search = SerialSearch(query={\"issn\": value.split(\" \")[0]})\n",
    "                                    search_result = search.results[0]\n",
    "                                    year = search_result.get(\"coverageStartYear\")\n",
    "                                data_dict[\"year\"] = year\n",
    "                            except:\n",
    "                                print(paper)\n",
    "                        else:\n",
    "                            data_dict[attr] = value\n",
    "                    else:\n",
    "                        count_none += 1\n",
    "                else:\n",
    "                    data_dict[attr] = \"\"\n",
    "        all_papers.append(data_dict)\n",
    "    return all_papers, count_none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_year = datetime.datetime.now().year\n",
    "year_digits = [int(digit) for digit in str(current_year)]\n",
    "print(\"Current Year:\", current_year)\n",
    "print(\"Year Digits:\", year_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year -= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\n",
    "    \"2016,2018\",\n",
    "    # \"2017,2019\",\n",
    "    # \"2019,2021\",\n",
    "    # \"2020,2022\",\n",
    "    # \"2021,2023\",\n",
    "    # \"2022,2024\",\n",
    "]\n",
    "super_all_paper = []\n",
    "\n",
    "for year in years:\n",
    "    query = f'TITLE({title}) AND PUBYEAR > {year.split(\",\")[0]} AND PUBYEAR < {year.split(\",\")[1]}' if title else f'PUBYEAR > {year.split(\",\")[0]} AND PUBYEAR < {year.split(\",\")[1]}'\n",
    "    url = f'https://api.elsevier.com/content/search/scopus?query={query}&apiKey={api_key}&httpAccept=application%2Fjson&count=1'\n",
    "    response = requests.get(url, headers)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            papers_from_search = json.loads(response.text)['search-results']['entry']\n",
    "            paper_nec_data, _ = get_paper_info(papers_from_search)\n",
    "            super_all_paper += paper_nec_data\n",
    "        except:\n",
    "            print(response.text)\n",
    "    else:\n",
    "        print(\"Error code\", response.status_code)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_all_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_title = []\n",
    "for paper in super_all_paper:\n",
    "    try:\n",
    "        references = paper[\"references\"]\n",
    "        all_title = []\n",
    "        for ref in references:\n",
    "            all_title.append(ref.title)\n",
    "        references_title.append(all_title)\n",
    "    except:\n",
    "        print(\"Error\", paper)\n",
    "        references_title.append(None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(super_all_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_all_paper[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json.dumps(super_all_paper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"api_key\": \"464f17417c90aff3a9e077e3952aece0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url='http://localhost:8000/scopus_api', json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.post(\"http://localhost:8000/scopus_api\", {\n",
    "    api_key: \"464f17417c90aff3a9e077e3952aece0\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "rd = redis.Redis(\n",
    "    host='localhost',\n",
    "    port=6379,\n",
    "    encoding=\"utf-8\",\n",
    "    decode_responses=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = rd.ping()\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rd.get('paper:raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor, keys = rd.scan(cursor=0, match='paper:cu*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor, keys = rd.scan(cursor=cursor, match='paper:*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = 0\n",
    "rd.set(1, \"yay\")\n",
    "rd.get(1)\n",
    "# cursor, keys = rd.scan(cursor=cursor, match='paper:*')\n",
    "# while cursor > 0:\n",
    "    # cursor, keys = rd.scan(cursor=cursor, match='username:*')  \n",
    "\n",
    "# for key in keys:\n",
    "#     print('found: ', key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_all_paper_temp_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(references_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(super_all_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ref_title\"] = references_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.drop([\"references\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'title': 'Title',\n",
    "    'abstract': 'Abstract',\n",
    "    'University': 'University',\n",
    "    'Country': 'Country',\n",
    "    'Index_authors': 'Index_authors',\n",
    "    'authkeywords': 'Keywords',\n",
    "    'publicationName': 'PublicationName',\n",
    "    'publisher': 'Publisher',\n",
    "    'Subject_Area': 'Subject_Area',\n",
    "    'Subject_Area_Code': 'Subject_Area_CodeType',\n",
    "    'subtypedescription': 'Citation_Type',\n",
    "    'citedby_count': 'Citation_Number',\n",
    "    'references_number': 'Reference_number',\n",
    "    'year': 'Year',\n",
    "    'ref_title': \"Reference_title\"\n",
    "}\n",
    "\n",
    "df_tmp.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"Reference_title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv('data_phase2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_all_paper_temp_json = json.loads(df_tmp.to_json(orient = 'records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(super_all_paper_temp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_all_paper_temp_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The hostname of this device is = \",platform.node())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "kafka_broker = 'localhost:9093'\n",
    "topic = 'test'\n",
    "\n",
    "# Producer\n",
    "producer_config = {\n",
    "    'bootstrap.servers': kafka_broker\n",
    "}\n",
    "\n",
    "producer = Producer(producer_config)\n",
    "\n",
    "# Function to send API request to Kafka\n",
    "def send_api_request_to_kafka(paper, key):\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log = {\n",
    "        \"timestamp\": now,\n",
    "        \"id\": key,\n",
    "        \"device\": platform.node(),\n",
    "        \"system\": platform.system(),\n",
    "        \"action\": f'Paper id: {key} has been added from user {platform.node()} in {platform.system()} at {now}',\n",
    "    }\n",
    "    producer.produce(topic, value=json.dumps(log))\n",
    "    producer.flush()  # Make sure to flush to send the messages immediately\n",
    "\n",
    "# Send API requests to Kafka\n",
    "key = 1\n",
    "for paper in tqdm(super_all_paper_temp_json):\n",
    "    send_api_request_to_kafka(paper, key)\n",
    "    key += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer\n",
    "consumer_config = {\n",
    "    'bootstrap.servers': kafka_broker,\n",
    "    'group.id': 'event_log_group',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "}\n",
    "\n",
    "consumer = Consumer(consumer_config)\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "# Consumer to receive messages from Kafka\n",
    "print('Running Consumer')\n",
    "logs = []\n",
    "count_null = 0\n",
    "\n",
    "try:\n",
    "    while count_null < 10:\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            print(\"Message from consumer is None\")\n",
    "            count_null += 1\n",
    "            continue\n",
    "        if msg.error():\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                print(KafkaError._PARTITION_EOF)\n",
    "                continue\n",
    "            else:\n",
    "                print(msg.error())\n",
    "                break\n",
    "        else:\n",
    "            log = json.loads(msg.value())\n",
    "            print(log)\n",
    "            logs.append(log)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(logs)\n",
    "df = pd.read_json(json_data)\n",
    "df.to_csv(\"events_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_super_all_paper_temp_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info >= (3, 6):\n",
    "    import zipfile\n",
    "else:\n",
    "    import zipfile36 as zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import from_json, col\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = StructType([\n",
    "#     StructField(\"Title\", StringType(), True),\n",
    "#     StructField(\"Abstract\", StringType(), True),\n",
    "#     StructField(\"University\", StringType(), True),\n",
    "#     StructField(\"Country\", StringType(), True),\n",
    "#     StructField(\"Index_authors\", StringType(), True),\n",
    "#     StructField(\"Keywords\", StringType(), True),\n",
    "#     StructField(\"PublicationName\", StringType(), True),\n",
    "#     StructField(\"Publisher\", StringType(), True),\n",
    "#     StructField(\"Subject_Area\", StringType(), True),\n",
    "#     StructField(\"Subject_Area_CodeType\", StringType(), True),\n",
    "#     StructField(\"Citation_Type\", StringType(), True),\n",
    "#     StructField(\"Citation_Number\", IntegerType(), True),\n",
    "#     StructField(\"Reference_number\", StringType(), True),\n",
    "#     StructField(\"Year\", StringType(), True),\n",
    "#     StructField(\"Reference_title\", StringType(), True),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.appName(\"ScopusDataProcessing\").config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1\").getOrCreate()\n",
    "# kafka_df = (\n",
    "#     spark.readStream\n",
    "#     .format(\"kafka\")\n",
    "#     .option(\"kafka.bootstrap.servers\", kafka_broker)\n",
    "#     .option(\"subscribe\", topic)\n",
    "#     .option(\"subscribe\", \"devices\")\n",
    "#     .option(\"startingOffsets\", \"earliest\")\n",
    "#     .load()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ScopusDataProcessing\").getOrCreate()\n",
    "\n",
    "# Define the schema for the incoming JSON messages\n",
    "schema = StructType([StructField(\"title\", StringType(), True),\n",
    "                     StructField(\"authors\", StringType(), True),\n",
    "                     StructField(\"abstract\", StringType(), True),\n",
    "                     # Add more fields as needed\n",
    "                     ])\n",
    "\n",
    "# Define the Kafka consumer\n",
    "df = (\n",
    "    spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_broker)\n",
    "    .option(\"subscribe\", topic)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "# Parse the JSON data from Kafka\n",
    "parsed_df = df.selectExpr(\"CAST(value AS STRING)\").select(from_json(\"value\", schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "# Perform transformations, filtering, or aggregations\n",
    "processed_df = parsed_df.filter(col(\"abstract\").isNotNull())  # Example: Filter out records without abstract\n",
    "\n",
    "# Define the query to write the processed data to an output sink (e.g., console)\n",
    "query = (\n",
    "    processed_df.writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"console\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# Await termination of the query\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.to_csv('data_phase1-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"Reference_title\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_filtered_list = [title != None for title in df_tmp[\"Reference_title\"][0]]\n",
    "\n",
    "filtered_titles = [title for title in df_tmp[\"Reference_title\"][0] if title is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['Clean_Reference_title'] = df_tmp['Reference_title'].apply(lambda titles: [title for title in df_tmp[\"Reference_title\"] if title != None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_phase1-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df_tmp, df1])\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop_duplicates(subset=['Title'], keep='first')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"Title\"].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_phase1.xlsv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data_phase1.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df, df1])\n",
    "# df3.drop_duplicates(subset=None, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data_phase2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2])\n",
    "df3.drop_duplicates(subset=None, inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.read_csv(\"data_phase1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_tmp.Title.values\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\"http://localhost:8000/scopus_api\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = json.loads(response.text)['search-results']['entry']\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AbstractRetrieval(\"2-s2.0-85171199378\", view='FULL')\n",
    "ab.subject_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "    \"affiliation\",\n",
    "    \"authors\",\n",
    "    \"authkeywords\",\n",
    "    \"publicationName\",\n",
    "    \"publisher\",\n",
    "    \"subject_areas\",\n",
    "    \"subtypedescription\",\n",
    "    \"citedby_count\",\n",
    "    \"references\",\n",
    "    \"issn\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = []\n",
    "count_none = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    data_dict = {}\n",
    "    if paper[\"eid\"]:\n",
    "        ab = AbstractRetrieval(paper[\"eid\"], view='FULL')\n",
    "        for attr in attributes:\n",
    "            \n",
    "            if hasattr(ab, attr):\n",
    "                value = getattr(ab, attr)\n",
    "                if value is not None:\n",
    "                    if attr == \"affiliation\":\n",
    "                        uni_aff = []\n",
    "                        country_aff = []\n",
    "                        for aff in value:\n",
    "                            uni_aff.append(aff.name)\n",
    "                            country_aff.append(aff.country)\n",
    "                        data_dict[\"University\"] = uni_aff\n",
    "                        data_dict[\"Country\"] = country_aff\n",
    "                    elif attr == \"authors\":\n",
    "                        index_author = []\n",
    "                        for author in value:\n",
    "                            index_author.append(author.indexed_name)\n",
    "                        data_dict[\"Index_authors\"] = index_author\n",
    "                    elif attr == \"subject_areas\":\n",
    "                        subject_area = []\n",
    "                        subject_area_code = []\n",
    "                        for subj in value:\n",
    "                            subject_area.append(subj.area)\n",
    "                            subject_area_code.append(subj.abbreviation)\n",
    "                        data_dict[\"Subject_Area\"] = subject_area\n",
    "                        data_dict[\"Subject_Area_Code\"] = subject_area_code\n",
    "                    elif attr == \"references\":\n",
    "                        data_dict[\"references_number\"] = len(ab.references)\n",
    "                    elif attr == \"issn\":\n",
    "                        try:\n",
    "                            pattern = r'\\b\\d{4}\\b'\n",
    "                            match = re.search(pattern, ab.abstract)\n",
    "                            if match:\n",
    "                                year = match.group()\n",
    "                            else:\n",
    "                                search = SerialSearch(query={\"issn\": value.split(\" \")[0]})\n",
    "                                search_result = search.results[0]\n",
    "                                year = search_result.get(\"coverageStartYear\")\n",
    "                            data_dict[\"year\"] = year\n",
    "                        except:\n",
    "                            print(paper)\n",
    "                    else:\n",
    "                        data_dict[attr] = value\n",
    "                else:\n",
    "                    count_none += 1\n",
    "            else:\n",
    "                data_dict[attr] = \"\"\n",
    "    all_papers.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"Elsevier Â© 2009 Elsevier B.V.The structural collapse of manganese-based materials during cycling greatly restricts its \"\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = r'\\b\\d{4}\\b'\n",
    "\n",
    "# Use re.search to find the match in the text\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "# Retrieve the matched year\n",
    "if match:\n",
    "    year = match.group()\n",
    "    print(f\"Year: {year}\")\n",
    "else:\n",
    "    print(\"Year not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineering_mapping = {\n",
    "    'CE': 'Civil Engineering',\n",
    "    'ENV': 'Environmental Engineering',\n",
    "    'BME': 'Biomedical Engineering',\n",
    "    'PE': 'Petroleum Engineering',\n",
    "    'METAL': 'Metallurgical Engineering',\n",
    "    'ME': 'Mechanical Engineering',\n",
    "    'EE': 'Electrical Engineering',\n",
    "    'CPE': 'Computer Engineering',\n",
    "    'OPTIC': 'Optical Engineering',\n",
    "    'NANO': 'Nano Engineering',\n",
    "    'CHE': 'Chemical Engineering',\n",
    "    'MATENG': 'Materials Engineering',\n",
    "    'AGRI': 'Agricultural Engineering',\n",
    "    'IE': 'Industrial Engineering',\n",
    "    'SAFETY': 'Safety Engineering',\n",
    "    'MATH': 'Mathematics and Statistics',\n",
    "    'MATSCI': 'Material Science'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject_Area2'] = df['Subject_Area'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subject_Area2'] = df['Subject_Area2'].apply(lambda codes: [engineering_mapping.get(code, 'Unknown') for code in codes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aff in ab.affiliation:\n",
    "    print(aff.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerialSearch(query={\"title\": \"Energy facilities: Management and design and technological innovations\"})\n",
    "search_result = search.results[0]\n",
    "\n",
    "result = search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get(\"coverageStartYear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(s.results).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '27594a4c1478f17ac42280535ab20312'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '27594a4c1478f17ac42280535ab20312'\n",
    "\n",
    "headers = {\n",
    "    'Accept':'application/json',\n",
    "    'X-ELS-APIKey': '27594a4c1478f17ac42280535ab20312'\n",
    "}\n",
    "\n",
    "query = 'SUBJAREA(ENGI) AND PUBYEAR > 2018 AND PUBYEAR < 2023'\n",
    "\n",
    "url = f'https://api.elsevier.com/content/search/scopus?query={query}&apiKey={api_key}&httpAccept=application%2Fjson'\n",
    "\n",
    "\n",
    "response = requests.get(url, headers)\n",
    "\n",
    "# pprint.pprint(response.text)\n",
    "\n",
    "# print(len(json.loads(response.text)['search-results']['entry']))\n",
    "pprint.pprint(json.loads(response.text)['search-results']['entry'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
